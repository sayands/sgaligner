<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SGAligner: Scene Alignment with 3D Scene Graphs">
  <meta name="keywords" content="SGAligner">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SGAligner üìê </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3004CBT85N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3004CBT85N');
</script>

<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SGAligner üìê
            <p class="title is-3 publication-title"> 3D Scene Alignment with Scene Graphs  </p>
            <h3 class="title is-4 publication-title">ICCV 2023</h3>
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sayands.github.io/">Sayan Deb Sarkar</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://miksik.co.uk/">Ondrej Miksik</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://people.inf.ethz.ch/marc.pollefeys/">Marc Pollefeys</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/d%C3%A1niel-bar%C3%A1th-3a489092/">Daniel Barath</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ir0.github.io/">Iro Armeni</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ETH Zurich,</span>
            <span class="author-block"><sup>2</sup>Microsoft Mixed Reality & AI Labs</span>
          </div>

          <span class="link-block">
            <a href="https://arxiv.org/abs/2304.14880" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fas fa-file-pdf"></i>
              </span>
              <span>Paper</span>
            </a>
          </span>

          <span class="link-block">
            <a href="https://github.com/sayands/sgaligner" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://github.com/sayands/sgaligner/#dataset-generation-hammer" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fas fa-database"></i>
              </span>
              <span>Dataset</span>
            </a>
          </span>

          <span class="link-block">
            <a href="https://github.com/sayands/sgaligner/#benchmark-chart_with_upwards_trend" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fas fa-chart-bar"></i>
              </span>
              <span>Benchmark</span>
            </a>
          </span>

          <span class="link-block">
            <a href="https://youtu.be/WvJMpjNJCcc" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-youtube"></i>
              </span>
              <span>Video</span>
            </a>
          </span>

          <span class="link-block">
            <a
              href="static/assets/conference_poster.pdf"
              class="external-link button is-normal is-rounded is-dark"
            >
              <span class="icon">
                <i class="fas fa-palette"></i>
              </span>
              <span>Poster</span>
            </a>
          </span>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" style="max-width:100%" /> <br> <br>
      <h2 class="subtitle has-text-centered">
        SGAligner aligns 3D scene graphs of environments using multi-modal learning and leverages the output for the 
        downstream task of 3D point cloud registration, 3D point cloud mosaicking, and 3D alignment of a point cloud in a larger map that
        contains changes
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- News. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">News üì∞</h2>
        <div class="content has-text-justified">
          <ul>
            <li><b>Sep 2023</b>: <a href="https://youtu.be/WvJMpjNJCcc">Video</a> presenting SGAligner released. </li>
            <li><b>Jul 2023</b>: SGAligner accepted to ICCV '23. </li>
            <li><b>May 2023</b>: SGAligner preprint released on <a href="https://arxiv.org/abs/2304.14880v1">arXiv</a>.
            </li>
            <li><b>Apr 2023</b>: <a href="https://github.com/sayands/sgaligner">Code</a> released.</li>
          </ul>
        </div>
      </div>
    </div>
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Building 3D scene graphs has recently emerged as a topic in scene representation for several embodied AI applications to represent 
            the world in a structured and rich manner. With their increased use in solving downstream tasks 
            (eg, navigation and room rearrangement), can we leverage and recycle them for creating 3D maps of environments, 
            a pivotal step in agent operation? We focus on the fundamental problem of aligning pairs of 3D scene graphs whose 
            overlap can range from zero to partial and can contain arbitrary changes.
          </p>
          <p>
            We propose <strong>SGAligner</strong>, the <strong>first</strong> method for aligning pairs of 3D scene 
            graphs that is robust to in-the-wild scenarios (ie, unknown overlap -- if any -- and changes in the environment). 
            We get inspired by multi-modality knowledge graphs and use contrastive learning to learn a joint, multi-modal embedding space. 
            We evaluate on the 3RScan dataset and further showcase that our method can be used for estimating the transformation between pairs of 3D scenes. 
            Since benchmarks for these tasks are missing, we create them on this dataset. 
            The code, benchmark, and trained models are available on the project website.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video üé¨</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/WvJMpjNJCcc" title="YouTube video player" frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

  <!-- Architecture Overview -->
  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-3"> <strong>Architecture</strong> Overview</h2>
      <div class="content has-text-centered">
        <img src="static/videos/sgaligner_architecture.gif" style="max-width:100%" />
        
      </div>
    </div>
  </div>

  <!-- Downstream Outputs -->
  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-3">Visual Outputs of Downstream Applications</h2>
      <div class="content has-text-centered">
        <img src="static/videos/sgaligner_registration.gif" style="max-width:100%" />
        <img src="static/videos/sgaligner_mosaicking.gif" style="max-width:100%" />
      </div>
    </div>
  </div>

  <!-- Poster. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-full-width">
      <h2 class="title is-3">Conference Poster</h2>
      <a href="static/assets/conference_poster.pdf"><img src="static/assets/conference_poster_preview.jpg" /></a>
    </div>
  </div>

  <!-- References -->
  <section class="section" id="references">
    <div class="container is-max-desktop content">
      <h2 class="title">References üìö</h2>
      [1] Wald et. al, <strong>RIO: 3D Object Instance Re-Localization in Changing Indoor Environments</strong>, <em>ICCV 
        2019 </em> <br>
      [2] Wald et. al, <strong>Learning 3D Semantic Scene Graphs from 3D Indoor Reconstructions</strong>,
        <em>CVPR 2020</em>
    </div>

  </section>
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX üôè</h2>
      <pre><code>
        @inproceedings{Sarkar_2023_ICCV,
          author    = {Sarkar, Sayan Deb and Miksik, Ondrej and Pollefeys, Marc and Barath, Daniel and Armeni, Iro},
          title     = {SGAligner: 3D Scene Alignment with Scene Graphs},
          booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
          month     = {October},
          year      = {2023},
          pages     = {21927-21937}
      }
      </code></pre>
    </div>
  </section>

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>
              <p>
                It borrows the source code of <a href="https://github.com/nerfies/nerfies.github.io">this website</a>.
                We would like to thank Utkarsh Sinha and Keunhong Park.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

</body>
</html>
